from app.services import PredictService
import redis
class Worker:
    def __init__(self, id_worker, args:dict):
        self.id_worker = id_worker
        self.args = args
    def getArguments(self):
        return self.args
    def getResult():
        pass

class PredictWorker(Worker):
    def __init__(self, session_id, message:str):
        self.session_id = session_id
        self.message = message
        super().args = dict(session_id = session_id, prompt = message)
    def getResult(self):
        redis_client = redis.StrictRedis(
                host='localhost',
                port=6379,
                db=0,
                decode_responses=True
            )
        model = PredictService().getModel()
        tokenizer = PredictService().getTokenizer()
        messages = [
            {"role": "user", "content": self.message}
        ]
        inputs = tokenizer.apply_chat_template(
            messages,
            tokenize = True,
            add_generation_prompt = True, # Must add for generation
            return_tensors = "pt",
        ).to("cuda")
        output_ids = model.generate(
            input_ids=inputs["input_ids"],
            max_new_tokens=128,
            temperature=0.7,
            do_sample=True,  # Sampling untuk hasil yang lebih variatif, atau gunakan `do_sample=False` untuk greedy decoding
        )

        # Dekode hasil secara langsung
        output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)
        redis_client.set(self.session_id, output_text)
